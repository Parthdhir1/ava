{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "warnings.simplefilter('ignore')\n",
    "sys.path.insert(0,'./bert')\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "import run_classifier_inmem_noexport\n",
    "from tensorflow.saved_model import tag_constants \n",
    "import pickle \n",
    "from bert import tokenization\n",
    "\n",
    "global NUM_CLASS = 5\n",
    "\n",
    "flags = tf.flags\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSess():\n",
    "    flags = tf.flags\n",
    "    FLAGS = flags.FLAGS\n",
    "\n",
    "    flags.DEFINE_string(\n",
    "        \"export_dir\", './exported_model_folder/',\n",
    "        \"The dir where the exported model has been written.\")\n",
    "    \n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file='./bert_embeddings/vocab.txt', do_lower_case=True)\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.saved_model.loader.load(sess, [tag_constants.SERVING], FLAGS.export_dir)\n",
    "    return sess, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_inmem(sess, FLAGS, tokenizer, question):\n",
    "    global NUM_CLASS\n",
    "    def append_feature(feature):\n",
    "        eval_features.append(feature)\n",
    "        eval_writer.process_feature(feature)\n",
    "        \n",
    "    examples = run_classifier_inmem_noexport.getinput(question)    \n",
    "    tmp_file = os.path.join('/tmp/', \"eval.tf_record\")\n",
    "    label_list = [str(x) for x in range(NUM_CLASS)]\n",
    "    \n",
    "    # write test sentence to tmp_file\n",
    "    run_classifier_inmem_noexport.file_based_convert_examples_to_features(examples, label_list, 128, tokenizer, tmp_file)    \n",
    "    \n",
    "    predict_input_fn = run_classifier_inmem_noexport.file_based_input_fn_builder(\n",
    "        input_file=tmp_file,\n",
    "        seq_length=128,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "\n",
    "\n",
    "    record_iterator = tf.python_io.tf_record_iterator(path=tmp_file)    \n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    tensor_input_ids = graph.get_tensor_by_name('input_ids_1:0')\n",
    "    tensor_input_mask = graph.get_tensor_by_name('input_mask_1:0')\n",
    "    tensor_label_ids = graph.get_tensor_by_name('label_ids_1:0')\n",
    "    tensor_segment_ids = graph.get_tensor_by_name('segment_ids_1:0')\n",
    "    tensor_outputs = graph.get_tensor_by_name('loss/Softmax:0')\n",
    "    \n",
    "    for sentence in record_iterator:\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(sentence)\n",
    "\n",
    "        unique_ids = example.features.feature['unique_ids'].int64_list.value\n",
    "        input_ids = example.features.feature['input_ids'].int64_list.value\n",
    "        input_mask = example.features.feature['input_mask'].int64_list.value\n",
    "        segment_ids = example.features.feature['segment_ids'].int64_list.value\n",
    "        label_ids = example.features.feature['label_ids'].int64_list.value\n",
    "\n",
    "\n",
    "        result = sess.run([tensor_outputs],feed_dict={\n",
    "            tensor_input_ids: np.array(input_ids).reshape(-1, 128),\n",
    "            tensor_input_mask: np.array(input_mask).reshape(-1, 128),\n",
    "            tensor_segment_ids: np.array(segment_ids).reshape(-1, 128),\n",
    "            tensor_label_ids: np.array(label_ids).reshape(-1, 1)\n",
    "        })  \n",
    "\n",
    "        return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-b57be3963672>:11: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./export_amelia/381class_10percent_dropout/variables/variables\n"
     ]
    }
   ],
   "source": [
    "global session\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "session, tokenizer = getSess()\n",
    "r = predict_inmem(session, FLAGS, tokenizer, 'How do you like the weather today?')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
