{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "warnings.simplefilter('ignore')\n",
    "sys.path.insert(0,'../bert')\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "import run_classifier_inmem_noexport\n",
    "from tensorflow.saved_model import tag_constants \n",
    "import pickle \n",
    "from bert import tokenization\n",
    "\n",
    "global NUM_CLASS\n",
    "\n",
    "NUM_CLASS=150\n",
    "\n",
    "flags = tf.flags\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSess():\n",
    "    flags = tf.flags\n",
    "    FLAGS = flags.FLAGS\n",
    "\n",
    "    flags.DEFINE_string(\n",
    "        \"export_dir\", '../../export_models/percent90/',\n",
    "        \"The dir where the exported model has been written.\")\n",
    "    \n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file='../../embeddings/uncased_L-12_H-768_A-12/vocab.txt', do_lower_case=True)\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.saved_model.loader.load(sess, [tag_constants.SERVING], FLAGS.export_dir)\n",
    "    return sess, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_inmem(sess, FLAGS, tokenizer, question):\n",
    "    global NUM_CLASS\n",
    "    def append_feature(feature):\n",
    "        eval_features.append(feature)\n",
    "        eval_writer.process_feature(feature)\n",
    "        \n",
    "    examples = run_classifier_inmem_noexport.getinput(question)    \n",
    "    tmp_file = os.path.join('/tmp/', \"eval.tf_record\")\n",
    "    label_list = [str(x) for x in range(NUM_CLASS)]\n",
    "    \n",
    "    # write test sentence to tmp_file\n",
    "    run_classifier_inmem_noexport.file_based_convert_examples_to_features(examples, label_list, 128, tokenizer, tmp_file)    \n",
    "    \n",
    "    predict_input_fn = run_classifier_inmem_noexport.file_based_input_fn_builder(\n",
    "        input_file=tmp_file,\n",
    "        seq_length=128,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "\n",
    "\n",
    "    record_iterator = tf.python_io.tf_record_iterator(path=tmp_file)    \n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    tensor_input_ids = graph.get_tensor_by_name('input_ids_1:0')\n",
    "    tensor_input_mask = graph.get_tensor_by_name('input_mask_1:0')\n",
    "    tensor_label_ids = graph.get_tensor_by_name('label_ids_1:0')\n",
    "    tensor_segment_ids = graph.get_tensor_by_name('segment_ids_1:0')\n",
    "    tensor_outputs = graph.get_tensor_by_name('loss/Softmax:0')\n",
    "    \n",
    "    for sentence in record_iterator:\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(sentence)\n",
    "\n",
    "        unique_ids = example.features.feature['unique_ids'].int64_list.value\n",
    "        input_ids = example.features.feature['input_ids'].int64_list.value\n",
    "        input_mask = example.features.feature['input_mask'].int64_list.value\n",
    "        segment_ids = example.features.feature['segment_ids'].int64_list.value\n",
    "        label_ids = example.features.feature['label_ids'].int64_list.value\n",
    "\n",
    "\n",
    "        result = sess.run([tensor_outputs],feed_dict={\n",
    "            tensor_input_ids: np.array(input_ids).reshape(-1, 128),\n",
    "            tensor_input_mask: np.array(input_mask).reshape(-1, 128),\n",
    "            tensor_segment_ids: np.array(segment_ids).reshape(-1, 128),\n",
    "            tensor_label_ids: np.array(label_ids).reshape(-1, 1)\n",
    "        })  \n",
    "\n",
    "        return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-9d0b39da5534>:11: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../../export_models/percent90/variables/variables\n",
      "INFO:tensorflow:Writing example 0 of 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-0\n",
      "INFO:tensorflow:tokens: [CLS] how do you like the weather today ? [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2129 2079 2017 2066 1996 4633 2651 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "WARNING:tensorflow:From <ipython-input-3-1bb10a88e72d>:21: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "global session\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "session, tokenizer = getSess()\n",
    "r = predict_inmem(session, FLAGS, tokenizer, 'How do you like the weather today?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00558537, 0.00369703, 0.00468001, 0.00498081, 0.0034646 ,\n",
       "       0.00451047, 0.00282442, 0.0040466 , 0.00530498, 0.00895857,\n",
       "       0.00584554, 0.00578684, 0.00510342, 0.00506804, 0.00249405,\n",
       "       0.00756115, 0.00357978, 0.00403121, 0.00266262, 0.00395891,\n",
       "       0.00523536, 0.00659561, 0.00527991, 0.01044015, 0.00446732,\n",
       "       0.00421282, 0.00630595, 0.00785989, 0.00552344, 0.00879134,\n",
       "       0.00563308, 0.00657231, 0.00400539, 0.00746097, 0.00917526,\n",
       "       0.00309761, 0.00461051, 0.00460911, 0.01036947, 0.00547472,\n",
       "       0.00421908, 0.0060829 , 0.00371816, 0.00331775, 0.00961806,\n",
       "       0.00519314, 0.00485394, 0.00579598, 0.00723409, 0.00923276,\n",
       "       0.00623235, 0.00673085, 0.01282593, 0.00733177, 0.01134854,\n",
       "       0.00794534, 0.00593088, 0.0044748 , 0.00737451, 0.00362329,\n",
       "       0.00319522, 0.0088563 , 0.00614929, 0.00430552, 0.00204635,\n",
       "       0.00412285, 0.00960202, 0.00883069, 0.0056582 , 0.00431228,\n",
       "       0.00727059, 0.00426049, 0.00588124, 0.00618076, 0.00730943,\n",
       "       0.00960039, 0.00377707, 0.00636034, 0.00579206, 0.00729546,\n",
       "       0.00564339, 0.00447837, 0.00243912, 0.00285263, 0.00704371,\n",
       "       0.00487364, 0.0075874 , 0.00757909, 0.00895317, 0.00700778,\n",
       "       0.01240854, 0.00504347, 0.00623142, 0.006059  , 0.00745656,\n",
       "       0.00615357, 0.00671563, 0.00584086, 0.00518844, 0.00418965,\n",
       "       0.00676609, 0.00674206, 0.00792055, 0.00843978, 0.0035498 ,\n",
       "       0.00375483, 0.00440503, 0.00499864, 0.00460545, 0.01164358,\n",
       "       0.00841892, 0.00723482, 0.0084081 , 0.00926687, 0.00725253,\n",
       "       0.00234541, 0.00580731, 0.01047188, 0.00569777, 0.01076763,\n",
       "       0.00947254, 0.01021908, 0.01124136, 0.0078827 , 0.00760762,\n",
       "       0.00611319, 0.01146184, 0.00782857, 0.00855951, 0.00367541,\n",
       "       0.00377352, 0.01114863, 0.00847355, 0.00509544, 0.00452022,\n",
       "       0.00513544, 0.00311319, 0.00375054, 0.00385352, 0.00752369,\n",
       "       0.06578013, 0.00511828, 0.0059277 , 0.00689442, 0.00671359,\n",
       "       0.00904235, 0.00327235, 0.00908571, 0.00788488, 0.00383329],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
